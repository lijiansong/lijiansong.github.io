<div class="message">
In heterogeneous computing, many programming models take use of computation offloading by transfering resource intensive computational tasks to an external platform, such as a cluster, grid or a cloud. Offloading may be necessary due to hardware limitations of a devices, such as limited computational power, storage, and energy. Here, we will make a birdview of the offloading action of CUDA and OpenMP in clang driver.
</div>
<p><!-- more --></p>

<h2 id="clang-offloading-action">Clang Offloading Action</h2>

<p>In clang, the offload action is expected to be used in four different situations:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
a) Set a toolchain/architecture/kind for a host action:

   Host Action 1 -&gt; OffloadAction -&gt; Host Action 2

b) Set a toolchain/architecture/kind for a device action;

   Device Action 1 -&gt; OffloadAction -&gt; Device Action 2

c) Specify a device dependence to a host action;

   Device Action 1  _
                     \
     Host Action 1  ---&gt; OffloadAction -&gt; Host Action 2

d) Specify a host dependence to a device action.

     Host Action 1  _
                     \
   Device Action 1  ---&gt; OffloadAction -&gt; Device Action 2

</code></pre></div></div>

<p>As is shown above, clang offloading actions take two design properties:</p>
<ul>
  <li>For a) and b), clang just returns the job generated for the dependence;</li>
  <li>For c) and d) clang overrides the current action with the host/device dependence if the current toolchain is host/device and set the offload dependences information with the jobs obtained from the device/host dependences.</li>
</ul>

<h2 id="cuda-offloading">CUDA offloading</h2>

<p>Let’s have an overview of cuda’s offloading. We can obtain the following action graph when compiling two source files for host and a CUDA device, namely kernel-call.cu and a.cpp:</p>

<p><img src="/assets/blog-img/2018_04_28_cuda_offload.png" alt="image" title="CUDA offloading example" /></p>

<p>As is shown from the figure above, if we are generating code for the device or we are in a backend phase, we attempt to generate a fat binary. Clang compiles each arch to <code class="highlighter-rouge">ptx and assemble to cubin</code>, then feed the <code class="highlighter-rouge">cubin and the ptx</code> into a device “link” action, which uses <code class="highlighter-rouge">cuda-fatbin</code> to combine these cubins into one fatbin.  The fatbin is then an input to the host action. During cuda device phase, clang creates an offloading action for backend and assembler action respectively. And an offload action is used to add a host dependence to the device linker actions.</p>

<p>By command <code class="highlighter-rouge">clang kernel-call.cu a.cpp -ccc-print-phases</code>, we will get following pipelined phases behind clang compiling:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0: input, "kernel-call.cu", cuda, (host-cuda)
1: preprocessor, {0}, cuda-cpp-output, (host-cuda)
2: compiler, {1}, ir, (host-cuda)
3: input, "kernel-call.cu", cuda, (device-cuda, sm_20)
4: preprocessor, {3}, cuda-cpp-output, (device-cuda, sm_20)
5: compiler, {4}, ir, (device-cuda, sm_20)
6: backend, {5}, assembler, (device-cuda, sm_20)
7: assembler, {6}, object, (device-cuda, sm_20)
8: offload, "device-cuda (nvptx64-nvidia-cuda:sm_20)" {7}, object
9: offload, "device-cuda (nvptx64-nvidia-cuda:sm_20)" {6}, assembler
10: linker, {8, 9}, cuda-fatbin, (device-cuda)
11: offload, "host-cuda (x86_64-apple-darwin17.2.0)" {2}, "device-cuda (nvptx64-nvidia-cuda)" {10}, ir
12: backend, {11}, assembler, (host-cuda)
13: assembler, {12}, object, (host-cuda)
14: input, "a.cpp", c++, (host-cuda)
15: preprocessor, {14}, c++-cpp-output, (host-cuda)
16: compiler, {15}, ir, (host-cuda)
17: backend, {16}, assembler, (host-cuda)
18: assembler, {17}, object, (host-cuda)
19: linker, {13, 18}, image, (host-cuda)
20: bind-arch, "x86_64", {19}, image
</code></pre></div></div>

<p>And we can get the following bindings result by typing command <code class="highlighter-rouge">clang kernel-call.cu a.cpp -ccc-print-bindings</code>:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># "nvptx64-nvidia-cuda" - "clang", inputs: ["kernel-call.cu"], output: "/var/folders/sp/yzrv8j5s4dg6mc4bgzvcc1h80000gn/T/kernel-call-10d9de.s"

# "nvptx64-nvidia-cuda" - "NVPTX::Assembler", inputs: ["/var/folders/sp/yzrv8j5s4dg6mc4bgzvcc1h80000gn/T/kernel-call-10d9de.s"], output: "/var/folders/sp/yzrv8j5s4dg6mc4bgzvcc1h80000gn/T/kernel-call-6a0708.o"

# "nvptx64-nvidia-cuda" - "NVPTX::Linker", inputs: ["/var/folders/sp/yzrv8j5s4dg6mc4bgzvcc1h80000gn/T/kernel-call-6a0708.o", "/var/folders/sp/yzrv8j5s4dg6mc4bgzvcc1h80000gn/T/kernel-call-10d9de.s"], output: "/var/folders/sp/yzrv8j5s4dg6mc4bgzvcc1h80000gn/T/kernel-call-c3b1ee.fatbin"

# "x86_64-apple-darwin17.2.0" - "clang", inputs: ["kernel-call.cu", "/var/folders/sp/yzrv8j5s4dg6mc4bgzvcc1h80000gn/T/kernel-call-c3b1ee.fatbin"], output: "/var/folders/sp/yzrv8j5s4dg6mc4bgzvcc1h80000gn/T/kernel-call-a9bed9.o"

# "x86_64-apple-darwin17.2.0" - "clang", inputs: ["a.cpp"], output: "/var/folders/sp/yzrv8j5s4dg6mc4bgzvcc1h80000gn/T/a-cfaee5.o"

# "x86_64-apple-darwin17.2.0" - "darwin::Linker", inputs: ["/var/folders/sp/yzrv8j5s4dg6mc4bgzvcc1h80000gn/T/kernel-call-a9bed9.o", "/var/folders/sp/yzrv8j5s4dg6mc4bgzvcc1h80000gn/T/a-cfaee5.o"], output: "a.out"

</code></pre></div></div>

<h2 id="openmp-offloading">OpenMP Offloading</h2>

<p>Another example is OpenMP, below is the action graph obtained when compiling two source files for host and an OpenMP device:</p>

<p><img src="/assets/blog-img/2018_04_28_openmp_offload.png" alt="image" title="OpenMP offloading example" /></p>

<p>As we can see, an offload action is used to add a host dependence to the device compile actions and add a device dependence to the host linking action<a href="#ibm_offload_paper">[2]</a>. The host depends on device action in the linking phase, when all the device images have to be embedded in the host image. Besides, when generating code for OpenMP, clang use the host compile phase output as a dependence to the device compile phase so that it can learn what declarations should be emitted.</p>

<p>For the source code of CUDA and OpenMP offloading action, see here: <a href="https://github.com/llvm-mirror/clang/blob/master/lib/Driver/Driver.cpp#L2127-L2538">https://github.com/llvm-mirror/clang/blob/master/lib/Driver/Driver.cpp#L2127-L2538</a></p>

<h2 id="ref">REF</h2>
<ul>
  <li>[1] OpenMP offloading support, slide: <a href="https://llvm-hpc3-workshop.github.io/slides/Bertolli.pdf">https://llvm-hpc3-workshop.github.io/slides/Bertolli.pdf</a></li>
  <li>[2] <span id="ibm_offload_paper">OpenMP offloading support, paper: <a href="https://researcher.watson.ibm.com/researcher/files/us-zsura/17_llvmATSC2016.pdf">https://researcher.watson.ibm.com/researcher/files/us-zsura/17_llvmATSC2016.pdf</a> </span></li>
  <li>[3] Generic Offload File Bundler Tool: <a href="http://clang-developers.42468.n3.nabble.com/RFC-OpenMP-CUDA-Generic-Offload-File-Bundler-Tool-td4050147.html">http://clang-developers.42468.n3.nabble.com/RFC-OpenMP-CUDA-Generic-Offload-File-Bundler-Tool-td4050147.html</a> and <a href="https://chromium.googlesource.com/external/github.com/llvm-mirror/clang/+/refs/heads/master/test/Driver/openmp-offload-gpu.c">example</a></li>
  <li>[4] Clang Driver Internals: <a href="https://clang.llvm.org/docs/DriverInternals.html">https://clang.llvm.org/docs/DriverInternals.html</a></li>
  <li>[5] Clang review: <a href="https://reviews.llvm.org/D21852">https://reviews.llvm.org/D21852</a></li>
  <li>[6] Calng review: <a href="https://www.mail-archive.com/cfe-commits@lists.llvm.org/msg36757.html">https://www.mail-archive.com/cfe-commits@lists.llvm.org/msg36757.html</a></li>
  <li>[7] [CUDA][OpenMP] Add a generic offload action builder: <a href="https://reviews.llvm.org/D18172">https://reviews.llvm.org/D18172</a> and revision: <a href="http://llvm.org/viewvc/llvm-project?view=revision&amp;revision=282865">http://llvm.org/viewvc/llvm-project?view=revision&amp;revision=282865</a></li>
  <li>[8] Clang Driver source code: <a href="https://github.com/llvm-mirror/clang/tree/master/lib/Driver">https://github.com/llvm-mirror/clang/tree/master/lib/Driver</a></li>
</ul>

<p>Any questions or suggestions, feel free to open an issue @<a href="https://github.com/lijiansong/clang-llvm-tutorial">here</a> or e-mail me to <em>lijiansong@ict.ac.cn</em>.</p>

