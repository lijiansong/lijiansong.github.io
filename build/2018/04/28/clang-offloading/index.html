<!DOCTYPE html><html lang=en> <head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge,chrome=1"><title>Offloading Actions in Clang Driver - /dev/posts/</title><meta name=viewport content="initial-scale=1.0, maximum-scale=2.0, minimum-scale=1.0, user-scalable=yes, width=device-width"><link rel=stylesheet href=/css/main.css></head> <body> <header> <h1>/dev/posts/</h1> </header> <nav> <ul> <li><a href=/ title=Home><i class="fa fa-home" aria-hidden=true></i> Home</a></li> <li><a href=https://github.com/lijiansong title="GitHub Projects"><i class="fa fa-github" aria-hidden=true></i> Projects</a></li> <li><a href=/tags/ title=Tags><i class="fa fa-tags" aria-hidden=true></i> Tags</a></li> <li><a href=/archives/ title=Archives><i class="fa fa-list" aria-hidden=true></i> Archives</a></li> <li><button title="Change theme" style="border: none; background:none;" onclick=toggleTheme();><i class="fa fa-toggle-on" aria-hidden=true></i></button></li> </ul> </nav> <main role=main> <section> <article> <header> <h1>Offloading Actions in Clang Driver</h1> <p> <time>Apr 28 2018</time></p> <p class=taglist> <a href=/tags/platform-tool/ rel=tag class="label label-default">platform-tool</a> </p> </header> <p>In heterogeneous computing, many programming models take use of computation offloading by transfering resource intensive computational tasks to an external platform, such as a cluster, grid or a cloud. Offloading may be necessary due to hardware limitations of a devices, such as limited computational power, storage, and energy. Here, we will make a birdview of the offloading action of CUDA and OpenMP in clang driver.</p> <h2>Clang Offloading Action</h2> <p>In clang, the offload action is expected to be used in four different situations:</p> <div class=codehilite><pre><span></span>a) Set a toolchain/architecture/kind for a host action:

   Host Action 1 -&gt; OffloadAction -&gt; Host Action 2

b) Set a toolchain/architecture/kind for a device action;

   Device Action 1 -&gt; OffloadAction -&gt; Device Action 2

c) Specify a device dependence to a host action;

   Device Action 1  _
                     \
     Host Action 1  ---&gt; OffloadAction -&gt; Host Action 2

d) Specify a host dependence to a device action.

     Host Action 1  _
                     \
   Device Action 1  ---&gt; OffloadAction -&gt; Device Action 2
</pre></div> <p>As is shown above, clang offloading actions take two design properties: - For a) and b), clang just returns the job generated for the dependence; - For c) and d) clang overrides the current action with the host/device dependence if the current toolchain is host/device and set the offload dependences information with the jobs obtained from the device/host dependences.</p> <h2>CUDA offloading</h2> <p>In clang driver module, the driver extensions for cuda mainly focuses on the support for CUDA by extending existing support with: - Host and device actions; - Selection of right toolchain per function based on <code>host, device, global</code> markups; - Linker tool (fatbinary) is used to combine objects for different compute capability(not nvlink); - Host action is used to embed device code into host-produced binary.</p> <p>Let's have an overview of cuda's offloading. We can obtain the following action graph when compiling two source files for host and a CUDA device, namely kernel-call.cu and a.cpp:</p> <p><img alt=image height=50% src=/blog-img/2018_04_28_cuda_offload.png title="CUDA offloading example" width=80%></p> <p>As is shown from the figure above, if we are generating code for the device or we are in a backend phase, we attempt to generate a fat binary. Clang compiles each arch to <code>ptx and assemble to cubin</code>, then feed the <code>cubin and the ptx</code> into a device "link" action, which uses <code>cuda-fatbin</code> to combine these cubins into one fatbin. The fatbin is then an input to the host action. During cuda device phase, clang creates an offloading action for backend and assembler action respectively. And an offload action is used to add a host dependence to the device linker actions.</p> <p>By <code>clang kernel-call.cu a.cpp -ccc-print-phases</code>, we will get following pipelined phases behind clang compiling:</p> <div class=codehilite><pre><span></span><span class=mi>0</span><span class=o>:</span> <span class=n>input</span><span class=o>,</span> <span class=s2>&quot;kernel-call.cu&quot;</span><span class=o>,</span> <span class=n>cuda</span><span class=o>,</span> <span class=o>(</span><span class=n>host</span><span class=o>-</span><span class=n>cuda</span><span class=o>)</span>
<span class=mi>1</span><span class=o>:</span> <span class=n>preprocessor</span><span class=o>,</span> <span class=o>{</span><span class=mi>0</span><span class=o>},</span> <span class=n>cuda</span><span class=o>-</span><span class=n>cpp</span><span class=o>-</span><span class=n>output</span><span class=o>,</span> <span class=o>(</span><span class=n>host</span><span class=o>-</span><span class=n>cuda</span><span class=o>)</span>
<span class=mi>2</span><span class=o>:</span> <span class=n>compiler</span><span class=o>,</span> <span class=o>{</span><span class=mi>1</span><span class=o>},</span> <span class=n>ir</span><span class=o>,</span> <span class=o>(</span><span class=n>host</span><span class=o>-</span><span class=n>cuda</span><span class=o>)</span>
<span class=mi>3</span><span class=o>:</span> <span class=n>input</span><span class=o>,</span> <span class=s2>&quot;kernel-call.cu&quot;</span><span class=o>,</span> <span class=n>cuda</span><span class=o>,</span> <span class=o>(</span><span class=n>device</span><span class=o>-</span><span class=n>cuda</span><span class=o>,</span> <span class=n>sm_20</span><span class=o>)</span>
<span class=mi>4</span><span class=o>:</span> <span class=n>preprocessor</span><span class=o>,</span> <span class=o>{</span><span class=mi>3</span><span class=o>},</span> <span class=n>cuda</span><span class=o>-</span><span class=n>cpp</span><span class=o>-</span><span class=n>output</span><span class=o>,</span> <span class=o>(</span><span class=n>device</span><span class=o>-</span><span class=n>cuda</span><span class=o>,</span> <span class=n>sm_20</span><span class=o>)</span>
<span class=mi>5</span><span class=o>:</span> <span class=n>compiler</span><span class=o>,</span> <span class=o>{</span><span class=mi>4</span><span class=o>},</span> <span class=n>ir</span><span class=o>,</span> <span class=o>(</span><span class=n>device</span><span class=o>-</span><span class=n>cuda</span><span class=o>,</span> <span class=n>sm_20</span><span class=o>)</span>
<span class=mi>6</span><span class=o>:</span> <span class=n>backend</span><span class=o>,</span> <span class=o>{</span><span class=mi>5</span><span class=o>},</span> <span class=n>assembler</span><span class=o>,</span> <span class=o>(</span><span class=n>device</span><span class=o>-</span><span class=n>cuda</span><span class=o>,</span> <span class=n>sm_20</span><span class=o>)</span>
<span class=mi>7</span><span class=o>:</span> <span class=n>assembler</span><span class=o>,</span> <span class=o>{</span><span class=mi>6</span><span class=o>},</span> <span class=n>object</span><span class=o>,</span> <span class=o>(</span><span class=n>device</span><span class=o>-</span><span class=n>cuda</span><span class=o>,</span> <span class=n>sm_20</span><span class=o>)</span>
<span class=mi>8</span><span class=o>:</span> <span class=n>offload</span><span class=o>,</span> <span class=s2>&quot;device-cuda (nvptx64-nvidia-cuda:sm_20)&quot;</span> <span class=o>{</span><span class=mi>7</span><span class=o>},</span> <span class=n>object</span>
<span class=mi>9</span><span class=o>:</span> <span class=n>offload</span><span class=o>,</span> <span class=s2>&quot;device-cuda (nvptx64-nvidia-cuda:sm_20)&quot;</span> <span class=o>{</span><span class=mi>6</span><span class=o>},</span> <span class=n>assembler</span>
<span class=mi>10</span><span class=o>:</span> <span class=n>linker</span><span class=o>,</span> <span class=o>{</span><span class=mi>8</span><span class=o>,</span> <span class=mi>9</span><span class=o>},</span> <span class=n>cuda</span><span class=o>-</span><span class=n>fatbin</span><span class=o>,</span> <span class=o>(</span><span class=n>device</span><span class=o>-</span><span class=n>cuda</span><span class=o>)</span>
<span class=mi>11</span><span class=o>:</span> <span class=n>offload</span><span class=o>,</span> <span class=s2>&quot;host-cuda (x86_64-apple-darwin17.2.0)&quot;</span> <span class=o>{</span><span class=mi>2</span><span class=o>},</span> <span class=s2>&quot;device-cuda (nvptx64-nvidia-cuda)&quot;</span> <span class=o>{</span><span class=mi>10</span><span class=o>},</span> <span class=n>ir</span>
<span class=mi>12</span><span class=o>:</span> <span class=n>backend</span><span class=o>,</span> <span class=o>{</span><span class=mi>11</span><span class=o>},</span> <span class=n>assembler</span><span class=o>,</span> <span class=o>(</span><span class=n>host</span><span class=o>-</span><span class=n>cuda</span><span class=o>)</span>
<span class=mi>13</span><span class=o>:</span> <span class=n>assembler</span><span class=o>,</span> <span class=o>{</span><span class=mi>12</span><span class=o>},</span> <span class=n>object</span><span class=o>,</span> <span class=o>(</span><span class=n>host</span><span class=o>-</span><span class=n>cuda</span><span class=o>)</span>
<span class=mi>14</span><span class=o>:</span> <span class=n>input</span><span class=o>,</span> <span class=s2>&quot;a.cpp&quot;</span><span class=o>,</span> <span class=n>c</span><span class=o>++,</span> <span class=o>(</span><span class=n>host</span><span class=o>-</span><span class=n>cuda</span><span class=o>)</span>
<span class=mi>15</span><span class=o>:</span> <span class=n>preprocessor</span><span class=o>,</span> <span class=o>{</span><span class=mi>14</span><span class=o>},</span> <span class=n>c</span><span class=o>++-</span><span class=n>cpp</span><span class=o>-</span><span class=n>output</span><span class=o>,</span> <span class=o>(</span><span class=n>host</span><span class=o>-</span><span class=n>cuda</span><span class=o>)</span>
<span class=mi>16</span><span class=o>:</span> <span class=n>compiler</span><span class=o>,</span> <span class=o>{</span><span class=mi>15</span><span class=o>},</span> <span class=n>ir</span><span class=o>,</span> <span class=o>(</span><span class=n>host</span><span class=o>-</span><span class=n>cuda</span><span class=o>)</span>
<span class=mi>17</span><span class=o>:</span> <span class=n>backend</span><span class=o>,</span> <span class=o>{</span><span class=mi>16</span><span class=o>},</span> <span class=n>assembler</span><span class=o>,</span> <span class=o>(</span><span class=n>host</span><span class=o>-</span><span class=n>cuda</span><span class=o>)</span>
<span class=mi>18</span><span class=o>:</span> <span class=n>assembler</span><span class=o>,</span> <span class=o>{</span><span class=mi>17</span><span class=o>},</span> <span class=n>object</span><span class=o>,</span> <span class=o>(</span><span class=n>host</span><span class=o>-</span><span class=n>cuda</span><span class=o>)</span>
<span class=mi>19</span><span class=o>:</span> <span class=n>linker</span><span class=o>,</span> <span class=o>{</span><span class=mi>13</span><span class=o>,</span> <span class=mi>18</span><span class=o>},</span> <span class=n>image</span><span class=o>,</span> <span class=o>(</span><span class=n>host</span><span class=o>-</span><span class=n>cuda</span><span class=o>)</span>
<span class=mi>20</span><span class=o>:</span> <span class=n>bind</span><span class=o>-</span><span class=n>arch</span><span class=o>,</span> <span class=s2>&quot;x86_64&quot;</span><span class=o>,</span> <span class=o>{</span><span class=mi>19</span><span class=o>},</span> <span class=n>image</span>
</pre></div> <p>And we can get the following bindings result by command <code>clang kernel-call.cu a.cpp -ccc-print-bindings</code>:</p> <div class=codehilite><pre><span></span># &quot;nvptx64-nvidia-cuda&quot; - &quot;clang&quot;, inputs: [&quot;kernel-call.cu&quot;], output: &quot;/var/folders/sp/yzrv8j5s4dg6mc4bgzvcc1h80000gn/T/kernel-call-10d9de.s&quot;

# &quot;nvptx64-nvidia-cuda&quot; - &quot;NVPTX::Assembler&quot;, inputs: [&quot;/var/folders/sp/yzrv8j5s4dg6mc4bgzvcc1h80000gn/T/kernel-call-10d9de.s&quot;], output: &quot;/var/folders/sp/yzrv8j5s4dg6mc4bgzvcc1h80000gn/T/kernel-call-6a0708.o&quot;

# &quot;nvptx64-nvidia-cuda&quot; - &quot;NVPTX::Linker&quot;, inputs: [&quot;/var/folders/sp/yzrv8j5s4dg6mc4bgzvcc1h80000gn/T/kernel-call-6a0708.o&quot;, &quot;/var/folders/sp/yzrv8j5s4dg6mc4bgzvcc1h80000gn/T/kernel-call-10d9de.s&quot;], output: &quot;/var/folders/sp/yzrv8j5s4dg6mc4bgzvcc1h80000gn/T/kernel-call-c3b1ee.fatbin&quot;

# &quot;x86_64-apple-darwin17.2.0&quot; - &quot;clang&quot;, inputs: [&quot;kernel-call.cu&quot;, &quot;/var/folders/sp/yzrv8j5s4dg6mc4bgzvcc1h80000gn/T/kernel-call-c3b1ee.fatbin&quot;], output: &quot;/var/folders/sp/yzrv8j5s4dg6mc4bgzvcc1h80000gn/T/kernel-call-a9bed9.o&quot;

# &quot;x86_64-apple-darwin17.2.0&quot; - &quot;clang&quot;, inputs: [&quot;a.cpp&quot;], output: &quot;/var/folders/sp/yzrv8j5s4dg6mc4bgzvcc1h80000gn/T/a-cfaee5.o&quot;

# &quot;x86_64-apple-darwin17.2.0&quot; - &quot;darwin::Linker&quot;, inputs: [&quot;/var/folders/sp/yzrv8j5s4dg6mc4bgzvcc1h80000gn/T/kernel-call-a9bed9.o&quot;, &quot;/var/folders/sp/yzrv8j5s4dg6mc4bgzvcc1h80000gn/T/a-cfaee5.o&quot;], output: &quot;a.out&quot;
</pre></div> <h2>OpenMP Offloading</h2> <p>Compared to CUDA, OpenMP has relocation of symbols across host/device and the dependencies between host and device toolchains is possible. Therefore, OpenMP takes the following offloading strategy. Below is the action graph obtained when compiling two source files for host and an OpenMP device:</p> <p><img alt=image height=100% src=/blog-img/2018_04_28_openmp_offload.png title="OpenMP offloading example" width=80%></p> <p>As we can see, an offload action is used to add a host dependence to the device compile actions and add a device dependence to the host linking action<a href=#ibm_offload_paper>[1]</a>. The host depends on device action in the linking phase, when all the device images have to be embedded in the host image. Besides, when generating code for OpenMP, clang use the host compile phase output as a dependence to the device compile phase so that it can learn what declarations should be emitted.</p> <p>Let's take OpenMP offloading for PPC64 and NVPTX64 for an example, the offloding graph is shown below:</p> <p><img alt=image height=100% src=/blog-img/2018_04_28_openmp_offload_ppc64_nvptx64.png title="OpenMP offloading for ppc64 and nvptx64" width=80%></p> <p>Here the LLVM IR for ppc64 target is the host bitcode file contains metadata that indicates what regions and functions should be compiled for device. And nvlink will link libomptarget-nvptx64 and the sass file dumped by ptxas. Here, Libomptarget-nvptx.bc will be precompiled with clang-cuda, and finally is the linking of various sections done by linker script which is generated by clang, and we will get a single <code>fat binary</code> for multiple devices, e.g. FPGA, DSP accelerator, GPU and etc.</p> <p>To sum up, in contrast with CUDA, the generic offloading action for OpenMP contains: - Replaces CUDAâ€™s host and device actions, including: - The offloading kind (e.g. OpenMP, CUDA) - The toolchain used by the dependencies (e.g. nvptx, amd) - Device architecture (e.g. sm_60) - Host to device dependency - The host builds a list of target regions to be compiled for device - Device to host dependency - Bundling of object code in single binary</p> <p>For the source code of CUDA and OpenMP offloading action, see here: <a href=https://github.com/llvm-mirror/clang/blob/master/lib/Driver/Driver.cpp#L2127-L2538>https://github.com/llvm-mirror/clang/blob/master/lib/Driver/Driver.cpp#L2127-L2538</a></p> <h2>REF</h2> <ul> <li>[1] <span id=ibm_offload_paper>OpenMP offloading support, <a href=https://researcher.watson.ibm.com/researcher/files/us-zsura/17_llvmATSC2016.pdf>paper</a> and <a href=https://llvm-hpc3-workshop.github.io/slides/Bertolli.pdf>slide</a>. </span></li> <li>[2] Generic Offload File Bundler Tool: <a href=http://clang-developers.42468.n3.nabble.com/RFC-OpenMP-CUDA-Generic-Offload-File-Bundler-Tool-td4050147.html>http://clang-developers.42468.n3.nabble.com/RFC-OpenMP-CUDA-Generic-Offload-File-Bundler-Tool-td4050147.html</a> and <a href=https://chromium.googlesource.com/external/github.com/llvm-mirror/clang/+/refs/heads/master/test/Driver/openmp-offload-gpu.c>example</a></li> <li>[3] Clang Driver Internals: <a href=https://clang.llvm.org/docs/DriverInternals.html>https://clang.llvm.org/docs/DriverInternals.html</a></li> <li>[4] Clang review: <a href=https://reviews.llvm.org/D21852>https://reviews.llvm.org/D21852</a></li> <li>[5] Calng review: <a href=https://www.mail-archive.com/cfe-commits@lists.llvm.org/msg36757.html>https://www.mail-archive.com/cfe-commits@lists.llvm.org/msg36757.html</a></li> <li>[6] [CUDA][OpenMP] Add a generic offload action builder: <a href=https://reviews.llvm.org/D18172>https://reviews.llvm.org/D18172</a> and revision: <a href="http://llvm.org/viewvc/llvm-project?view=revision&revision=282865">http://llvm.org/viewvc/llvm-project?view=revision&amp;revision=282865</a></li> <li>[7] Clang Driver source code: <a href=https://github.com/llvm-mirror/clang/tree/master/lib/Driver>https://github.com/llvm-mirror/clang/tree/master/lib/Driver</a></li> </ul> <p>Any questions or suggestions, feel free to open an issue @<a href=https://github.com/lijiansong/clang-llvm-tutorial>here</a> or e-mail me to <em>lijiansong@ict.ac.cn</em>.</p> </article> </section> </main> <footer> <form action=https://duckduckgo.com/ role=search> <input type=hidden name=sites value=lijiansong.github.io> <input type=hidden name=kae value=-1 id=_ddg_theme> <input role=searchbox name=q aria-label=Search placeholder="Search with DuckDuckGo..."> <button type=submit>Search</button> </form> <p><small> <a href=/about/ >About</a> - Powered by <a lang=fr href=https://github.com/middleman/middleman>Middleman</a> and <a href=https://github.com/FortAwesome/Font-Awesome>Font-Awesome</a> - <a href="mailto:lijiansong AT ict DOT ac DOT cn?subject=[Comment for http://github.com/lijiansong/2018/04/28/clang-offloading/]">Q & A</a> </small></p> </footer> <script src=/js/main.js></script> </body> </html>